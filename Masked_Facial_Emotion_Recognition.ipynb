{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Construction and Analysis\n",
    "\n",
    "### 3.1 Dataset Overview\n",
    "\n",
    "Our dataset combines:\n",
    "- **Base dataset**: FER2013 with synthetic mask overlays\n",
    "- **Metadata**: Age, gender, and ethnicity predictions using DeepFace\n",
    "- **Emotion categories**: 7 categories (angry, disgust, fear, happy, neutral, sad, surprise)\n",
    "- **Image format**: 48x48 grayscale images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the dataset\n",
    "df = pd.read_csv(\"facial_emotion_dataset_with_metadata.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze emotion distribution\n",
    "emotion_counts = df['emotion'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "emotion_counts.plot(kind='bar')\n",
    "plt.title('Emotion Distribution')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(emotion_counts.values, labels=emotion_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Emotion Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Emotion distribution:\")\n",
    "print(emotion_counts)\n",
    "print(f\"\\nClass imbalance ratio: {emotion_counts.max() / emotion_counts.min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze demographic distribution\n",
    "def extract_gender(gender_dict):\n",
    "    try:\n",
    "        return list(eval(gender_dict).keys())[0]\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "df['gender_label'] = df['gender'].apply(extract_gender)\n",
    "\n",
    "# Create visualizations for demographics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Age distribution\n",
    "axes[0, 0].hist(df['age'], bins=20, edgecolor='black')\n",
    "axes[0, 0].set_title('Age Distribution')\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = df['gender_label'].value_counts()\n",
    "axes[0, 1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 1].set_title('Gender Distribution')\n",
    "\n",
    "# Ethnicity distribution\n",
    "ethnicity_counts = df['ethnicity'].value_counts()\n",
    "axes[1, 0].bar(range(len(ethnicity_counts)), ethnicity_counts.values)\n",
    "axes[1, 0].set_title('Ethnicity Distribution')\n",
    "axes[1, 0].set_xticks(range(len(ethnicity_counts)))\n",
    "axes[1, 0].set_xticklabels(ethnicity_counts.index, rotation=45)\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "\n",
    "# Emotion vs Gender crosstab\n",
    "emotion_gender = pd.crosstab(df['emotion'], df['gender_label'])\n",
    "sns.heatmap(emotion_gender, annot=True, fmt='d', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Emotion vs Gender Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each emotion category\n",
    "def process_pixels(pixel_str):\n",
    "    return np.array(list(map(int, pixel_str.split())), dtype=np.uint8)\n",
    "\n",
    "# Convert pixel strings to numpy arrays\n",
    "df['pixels_array'] = df['pixels'].apply(process_pixels)\n",
    "\n",
    "# Display sample images\n",
    "emotions = df['emotion'].unique()\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, emotion in enumerate(emotions):\n",
    "    if i < len(axes):\n",
    "        sample = df[df['emotion'] == emotion].iloc[0]\n",
    "        img = sample['pixels_array'].reshape(48, 48)\n",
    "        \n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f'{emotion.capitalize()}\\nAge: {sample[\"age\"]}, Gender: {sample[\"gender_label\"]}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "# Remove extra subplot\n",
    "if len(emotions) < len(axes):\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "plt.suptitle('Sample Images from Each Emotion Category', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image data\n",
    "X_img = np.stack(df['pixels_array'].values)\n",
    "X_img = X_img.reshape(-1, 48, 48, 1) / 255.0  # Normalize to [0,1]\n",
    "\n",
    "# Encode emotion labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['emotion'])\n",
    "y_cat = to_categorical(y)\n",
    "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "print(\"Label encoding map:\")\n",
    "print(label_map)\n",
    "print(f\"\\nImage data shape: {X_img.shape}\")\n",
    "print(f\"Label data shape: {y_cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare metadata features\n",
    "gender_dummies = pd.get_dummies(df['gender_label'], prefix='gender')\n",
    "ethnicity_dummies = pd.get_dummies(df['ethnicity'], prefix='ethnicity')\n",
    "df['age_norm'] = df['age'] / df['age'].max()\n",
    "\n",
    "X_meta = pd.concat([\n",
    "    df['age_norm'],\n",
    "    gender_dummies,\n",
    "    ethnicity_dummies\n",
    "], axis=1).values.astype(np.float32)\n",
    "\n",
    "print(f\"Metadata features shape: {X_meta.shape}\")\n",
    "print(f\"Metadata features: {pd.concat([df['age_norm'], gender_dummies, ethnicity_dummies], axis=1).columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with stratification\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, val_index in sss.split(X_img, y):\n",
    "    X_train_img, X_val_img = X_img[train_index], X_img[val_index]\n",
    "    X_train_meta, X_val_meta = X_meta[train_index], X_meta[val_index]\n",
    "    y_train, y_val = y_cat[train_index], y_cat[val_index]\n",
    "    y_train_labels, y_val_labels = y[train_index], y[val_index]\n",
    "\n",
    "print(f\"Training set: {X_train_img.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val_img.shape[0]} samples\")\n",
    "\n",
    "# Compute class weights for handling imbalanced data\n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights_array))\n",
    "print(f\"\\nClass weights: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Design and Architecture\n",
    "\n",
    "### 4.1 Architecture Overview\n",
    "\n",
    "Our multitask learning architecture consists of:\n",
    "\n",
    "1. **Image Processing Branch**: CNN layers for spatial feature extraction\n",
    "2. **Metadata Processing Branch**: Dense layers for demographic features\n",
    "3. **Feature Fusion**: Concatenation of image and metadata features\n",
    "4. **Classification Head**: Softmax output for emotion prediction\n",
    "\n",
    "### 4.2 Design Rationale\n",
    "\n",
    "- **CNN Architecture**: Multiple Conv2D layers with BatchNormalization and Dropout\n",
    "- **Multitask Learning**: Leverages demographic information to improve emotion recognition\n",
    "- **Regularization**: Dropout and BatchNormalization to prevent overfitting\n",
    "- **Loss Function**: Categorical crossentropy with class weighting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation setup\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train_img)\n",
    "\n",
    "print(\"Data augmentation parameters:\")\n",
    "print(f\"- Rotation range: ±15 degrees\")\n",
    "print(f\"- Shift range: ±10% width/height\")\n",
    "print(f\"- Zoom range: ±10%\")\n",
    "print(f\"- Horizontal flip: Enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the multitask CNN model\n",
    "def create_emotion_model(input_shape, meta_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a multitask CNN model for emotion recognition\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input images (48, 48, 1)\n",
    "        meta_shape: Shape of metadata features\n",
    "        num_classes: Number of emotion classes\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Image input branch\n",
    "    img_input = Input(shape=input_shape, name='image_input')\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Third convolutional block\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Flatten image features\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Metadata input branch\n",
    "    meta_input = Input(shape=(meta_shape,), name='metadata_input')\n",
    "    m = Dense(32, activation='relu')(meta_input)\n",
    "    m = Dropout(0.3)(m)\n",
    "    \n",
    "    # Combine image and metadata features\n",
    "    combined = concatenate([x, m])\n",
    "    \n",
    "    # Classification head\n",
    "    z = Dense(128, activation='relu')(combined)\n",
    "    z = Dropout(0.5)(z)\n",
    "    z = Dense(64, activation='relu')(z)\n",
    "    z = Dropout(0.3)(z)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(num_classes, activation='softmax', name='emotion_output')(z)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model(inputs=[img_input, meta_input], outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_emotion_model(\n",
    "    input_shape=(48, 48, 1),\n",
    "    meta_shape=X_meta.shape[1],\n",
    "    num_classes=y_cat.shape[1]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation\n",
    "\n",
    "### 5.1 Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "PATIENCE = 10\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=PATIENCE, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"- Epochs: {EPOCHS}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Early stopping patience: {PATIENCE}\")\n",
    "print(f\"- Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"- Loss: Categorical crossentropy\")\n",
    "print(f\"- Class weighting: Enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "history = model.fit(\n",
    "    x=[X_train_img, X_train_meta],\n",
    "    y=y_train,\n",
    "    validation_data=([X_val_img, X_val_meta], y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation accuracy and loss\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "    ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "    ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "y_pred_proba = model.predict([X_val_img, X_val_meta])\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "val_accuracy = np.mean(y_pred == y_val_labels)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "emotion_names = label_encoder.classes_\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_val_labels, y_pred, target_names=emotion_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val_labels, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Raw confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=emotion_names, yticklabels=emotion_names, ax=ax1)\n",
    "ax1.set_title('Confusion Matrix (Raw Counts)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "ax1.set_ylabel('True Label')\n",
    "\n",
    "# Normalized confusion matrix\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',\n",
    "            xticklabels=emotion_names, yticklabels=emotion_names, ax=ax2)\n",
    "ax2.set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "ax2.set_ylabel('True Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"\\nPer-class Accuracies:\")\n",
    "for emotion, acc in zip(emotion_names, class_accuracies):\n",
    "    print(f\"{emotion:10s}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Bias Analysis\n",
    "\n",
    "We analyze model performance across different demographic groups to identify potential biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias analysis across demographic groups\n",
    "def analyze_bias(y_true, y_pred, demographic_data, demographic_name):\n",
    "    \"\"\"\n",
    "    Analyze model performance across demographic groups\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for group in demographic_data.unique():\n",
    "        if pd.isna(group) or group == 'Unknown':\n",
    "            continue\n",
    "            \n",
    "        mask = demographic_data == group\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        group_accuracy = np.mean(y_true[mask] == y_pred[mask])\n",
    "        group_size = mask.sum()\n",
    "        \n",
    "        results.append({\n",
    "            'Group': group,\n",
    "            'Accuracy': group_accuracy,\n",
    "            'Sample_Size': group_size\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{demographic_name} Bias Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Calculate bias metrics\n",
    "    max_acc = results_df['Accuracy'].max()\n",
    "    min_acc = results_df['Accuracy'].min()\n",
    "    bias_ratio = max_acc / min_acc\n",
    "    \n",
    "    print(f\"\\nBias Metrics:\")\n",
    "    print(f\"Max Accuracy: {max_acc:.4f}\")\n",
    "    print(f\"Min Accuracy: {min_acc:.4f}\")\n",
    "    print(f\"Bias Ratio: {bias_ratio:.4f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Get validation set demographics\n",
    "val_df = df.iloc[val_index].copy()\n",
    "val_df['predicted_emotion'] = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Gender bias analysis\n",
    "gender_bias = analyze_bias(y_val_labels, y_pred, val_df['gender_label'], 'Gender')\n",
    "\n",
    "# Ethnicity bias analysis\n",
    "ethnicity_bias = analyze_bias(y_val_labels, y_pred, val_df['ethnicity'], 'Ethnicity')\n",
    "\n",
    "# Age group bias analysis\n",
    "val_df['age_group'] = pd.cut(val_df['age'], bins=[0, 25, 35, 50, 100], labels=['Young', 'Adult', 'Middle-aged', 'Senior'])\n",
    "age_bias = analyze_bias(y_val_labels, y_pred, val_df['age_group'], 'Age Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bias analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Gender bias visualization\n",
    "axes[0].bar(gender_bias['Group'], gender_bias['Accuracy'])\n",
    "axes[0].set_title('Accuracy by Gender', fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Ethnicity bias visualization\n",
    "axes[1].bar(ethnicity_bias['Group'], ethnicity_bias['Accuracy'])\n",
    "axes[1].set_title('Accuracy by Ethnicity', fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Age group bias visualization\n",
    "axes[2].bar(age_bias['Group'], age_bias['Accuracy'])\n",
    "axes[2].set_title('Accuracy by Age Group', fontweight='bold')\n",
    "axes[2].set_ylabel('Accuracy')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Additional Features\n",
    "\n",
    "### 6.1 Model Comparison\n",
    "\n",
    "We compare our multitask model with a baseline CNN-only model to demonstrate the benefits of incorporating demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline CNN-only model for comparison\n",
    "def create_baseline_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a baseline CNN model without metadata\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train baseline model\n",
    "baseline_model = create_baseline_model((48, 48, 1), y_cat.shape[1])\n",
    "\n",
    "print(\"Training baseline CNN model (image only)...\")\n",
    "baseline_history = baseline_model.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=20,  # Fewer epochs for comparison\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate baseline model\n",
    "baseline_pred = baseline_model.predict(X_val_img)\n",
    "baseline_pred_labels = np.argmax(baseline_pred, axis=1)\n",
    "baseline_accuracy = np.mean(baseline_pred_labels == y_val_labels)\n",
    "\n",
    "print(f\"\\nModel Comparison:\")\n",
    "print(f\"Multitask Model Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Baseline CNN Accuracy:    {baseline_accuracy:.4f}\")\n",
    "print(f\"Improvement:              {val_accuracy - baseline_accuracy:.4f} ({((val_accuracy/baseline_accuracy)-1)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction confidence by emotion\n",
    "confidence_by_emotion = {}\n",
    "for i, emotion in enumerate(emotion_names):\n",
    "    mask = y_val_labels == i\n",
    "    if mask.sum() > 0:\n",
    "        confidences = y_pred_proba[mask, i]\n",
    "        confidence_by_emotion[emotion] = {\n",
    "            'mean_confidence': np.mean(confidences),\n",
    "            'std_confidence': np.std(confidences),\n",
    "            'count': mask.sum()\n",
    "        }\n",
    "\n",
    "# Plot confidence analysis\n",
    "emotions = list(confidence_by_emotion.keys())\n",
    "mean_conf = [confidence_by_emotion[e]['mean_confidence'] for e in emotions]\n",
    "std_conf = [confidence_by_emotion[e]['std_confidence'] for e in emotions]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(emotions, mean_conf, yerr=std_conf, capsize=5, alpha=0.7)\n",
    "plt.title('Model Confidence by Emotion Category', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Average Confidence')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, conf in zip(bars, mean_conf):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{conf:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Confidence Analysis:\")\n",
    "for emotion, stats in confidence_by_emotion.items():\n",
    "    print(f\"{emotion:10s}: {stats['mean_confidence']:.4f} ± {stats['std_confidence']:.4f} (n={stats['count']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassified samples\n",
    "misclassified_mask = y_pred != y_val_labels\n",
    "misclassified_indices = np.where(misclassified_mask)[0]\n",
    "\n",
    "print(f\"Total misclassified samples: {len(misclassified_indices)} / {len(y_val_labels)}\")\n",
    "print(f\"Misclassification rate: {len(misclassified_indices) / len(y_val_labels):.4f}\")\n",
    "\n",
    "# Show some misclassified examples\n",
    "if len(misclassified_indices) > 0:\n",
    "    n_examples = min(8, len(misclassified_indices))\n",
    "    sample_indices = np.random.choice(misclassified_indices, n_examples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img = X_val_img[idx].reshape(48, 48)\n",
    "        true_label = emotion_names[y_val_labels[idx]]\n",
    "        pred_label = emotion_names[y_pred[idx]]\n",
    "        confidence = y_pred_proba[idx, y_pred[idx]]\n",
    "        \n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}', \n",
    "                         fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Misclassified Examples', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Deployment and Application\n",
    "\n",
    "### 7.1 Model Saving and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('masked_emotion_recognition_model.h5')\n",
    "print(\"✅ Model saved as 'masked_emotion_recognition_model.h5'\")\n",
    "\n",
    "# Save label encoder\n",
    "import joblib\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "print(\"✅ Label encoder saved as 'label_encoder.pkl'\")\n",
    "\n",
    "# Save model metadata\n",
    "model_metadata = {\n",
    "    'emotion_classes': emotion_names.tolist(),\n",
    "    'input_shape': (48, 48, 1),\n",
    "    'metadata_features': pd.concat([df['age_norm'], gender_dummies, ethnicity_dummies], axis=1).columns.tolist(),\n",
    "    'validation_accuracy': float(val_accuracy),\n",
    "    'training_epochs': len(history.history['accuracy'])\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('model_metadata.json', 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "print(\"✅ Model metadata saved as 'model_metadata.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 GUI Application Preview\n",
    "\n",
    "Our project includes a comprehensive GUI application (`advanced_emotion_gui.py`) that provides:\n",
    "\n",
    "- **User-friendly interface** for image upload and webcam input\n",
    "- **Real-time emotion prediction** with confidence scores\n",
    "- **Demographic analysis** (age and gender prediction)\n",
    "- **Progress indicators** for better user experience\n",
    "\n",
    "The application demonstrates practical deployment of our trained model for real-world use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate model inference function\n",
    "def predict_emotion_with_demographics(image_path, model, label_encoder):\n",
    "    \"\"\"\n",
    "    Predict emotion from a masked face image\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        model: Trained Keras model\n",
    "        label_encoder: Fitted label encoder\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with prediction results\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return {\"error\": \"Could not load image\"}\n",
    "    \n",
    "    # Resize and normalize\n",
    "    img = cv2.resize(img, (48, 48))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    \n",
    "    # Create dummy metadata (in real application, this would come from user input or another model)\n",
    "    dummy_meta = np.zeros((1, X_meta.shape[1]))\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict([img, dummy_meta], verbose=0)\n",
    "    \n",
    "    # Get results\n",
    "    emotion_idx = np.argmax(predictions[0])\n",
    "    confidence = float(np.max(predictions[0]))\n",
    "    emotion = label_encoder.classes_[emotion_idx]\n",
    "    \n",
    "    # Get all probabilities\n",
    "    all_probs = {label_encoder.classes_[i]: float(predictions[0][i]) \n",
    "                for i in range(len(label_encoder.classes_))}\n",
    "    \n",
    "    return {\n",
    "        \"emotion\": emotion,\n",
    "        \"confidence\": confidence,\n",
    "        \"all_probabilities\": all_probs\n",
    "    }\n",
    "\n",
    "# Example usage (you would need an actual image file)\n",
    "print(\"Inference function ready for deployment!\")\n",
    "print(\"\\nExample output structure:\")\n",
    "example_output = {\n",
    "    \"emotion\": \"happy\",\n",
    "    \"confidence\": 0.8542,\n",
    "    \"all_probabilities\": {\n",
    "        \"angry\": 0.0123,\n",
    "        \"disgust\": 0.0098,\n",
    "        \"fear\": 0.0234,\n",
    "        \"happy\": 0.8542,\n",
    "        \"neutral\": 0.0567,\n",
    "        \"sad\": 0.0289,\n",
    "        \"surprise\": 0.0147\n",
    "    }\n",
    "}\n",
    "print(json.dumps(example_output, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
